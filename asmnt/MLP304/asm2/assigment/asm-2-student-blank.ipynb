{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "In this section we will have an original task: Given a question, how do you know if it was a genuine question from someone who are searching for an answer, or merely asked for some other reasons?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Data\n",
    "### Load libraries\n",
    "\n",
    "Nothing new here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset\n",
    "\n",
    "The dataset is part of **Quora's <a href=\"https://www.kaggle.com/c/quora-insincere-questions-classification/data\">Insincere Questions Classification</a> Competition**. You are free to explore the data as you see fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train.csv\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of questions: 1306122\n",
      "Insincere percentile: 6.19%\n",
      "Sample question (idx=6000): What starters should a person avoid when engaging a conversation?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00004f9a462a357c33be</td>\n",
       "      <td>Is Gaza slowly becoming Auschwitz, Dachau or T...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00005059a06ee19e11ad</td>\n",
       "      <td>Why does Quora automatically ban conservative ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0000559f875832745e2e</td>\n",
       "      <td>Is it crazy if I wash or wipe my groceries off...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00005bd3426b2d0c8305</td>\n",
       "      <td>Is there such a thing as dressing moderately, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00006e6928c5df60eacb</td>\n",
       "      <td>Is it just me or have you ever been in this ph...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "5  00004f9a462a357c33be  Is Gaza slowly becoming Auschwitz, Dachau or T...   \n",
       "6  00005059a06ee19e11ad  Why does Quora automatically ban conservative ...   \n",
       "7  0000559f875832745e2e  Is it crazy if I wash or wipe my groceries off...   \n",
       "8  00005bd3426b2d0c8305  Is there such a thing as dressing moderately, ...   \n",
       "9  00006e6928c5df60eacb  Is it just me or have you ever been in this ph...   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "5       0  \n",
       "6       0  \n",
       "7       0  \n",
       "8       0  \n",
       "9       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of questions: {:d}\".format(len(data)))\n",
    "print(\"Insincere percentile: {:.2f}%\".format( float(len(data[data[\"target\"] == 1])) / len(data) * 100.0))\n",
    "print(\"Sample question (idx=6000): {:s}\".format(data.iloc[6000][\"question_text\"]))\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling\n",
    "\n",
    "We can reduce the number of samples used in order to make the process faster, but this isn't proper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of questions (sample): 130612\n",
      "Insincere percentile (sample): 6.19%\n"
     ]
    }
   ],
   "source": [
    "sample_data = data.sample(frac=0.1, random_state=13)\n",
    "print(\"Number of questions (sample): {:d}\".format(len(sample_data)))\n",
    "print(\"Insincere percentile (sample): {:.2f}%\".format( float(len(sample_data[sample_data[\"target\"] == 1])) / len(sample_data) * 100.0))\n",
    "data = sample_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "\n",
    "Unlike in our usual working on perfect data during the course, the `question_text` field had not yet tokenized. If you just blindly put them into a model, the performance would be atrocious (for, say, <u>conversation?</u> will be counted as a single token instead of two tokens <u>conversation</u> and <u>?</u>). Good thing that the questions are in english, and we already have a well-trusted tool for this matter: <a href=\"\">NLTK</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "data = data.rename(columns={\"question_text\": \"raw_text\"})\n",
    "data[\"tokenized_text\"] = data[\"raw_text\"].map(lambda raw_text: (\" \".join(word_tokenize(raw_text.strip()))).lower())\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common topic modeling choices\n",
    "### Build a model on the data\n",
    "\n",
    "The easiest way to go on is to use good old sklearn's LDA as we learned them (<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html\">link</a>). Use CountVectorizer and LDA to search for underlying topics in the data. For this problem, we will assume to have 25 topics presented in the data.\n",
    "\n",
    "*Note: The prefered arguments for CountVectorizer are max_df=0.98, min_df=5, ngram_range=(1, 2), stop_words=\"english\". This avoid stop words, construct 2-grams and remove both too frequent and infrequent words. However, students are free to choose the arguments in general.*\n",
    "\n",
    "Also, keep the component distribution. You will be grateful of it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of topics\n",
    "topic_count = 25\n",
    "# Construct the CountVectorizer and create word count matrix\n",
    "\n",
    "# fit transform the LDA model on the word count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpret the topics generated\n",
    "\n",
    "You are free to do whatever you want to demonstrate the topics that had been chosen. Our recommended practice is to use a function to extract the values per words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of insincere questions\n",
    "\n",
    "Alright, that's a pretty neat division of topics you might have there, but how do we apply it to our problem? It turns out that while all topics is equal, some just attract far more junk than the other. Calculate the percentage of insincere questions per each topics.\n",
    "\n",
    "The code below assumes that you already have a variable `distribution` of shape *\\[num_samples, topic_count\\]* denoting the topic distribution for each sample. If you don't have any such values, please modify the code as you see fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0 insincere percentage: 7.38%\n",
      "Topic 1 insincere percentage: 6.59%\n",
      "Topic 2 insincere percentage: 12.26%\n",
      "Topic 3 insincere percentage: 4.47%\n",
      "Topic 4 insincere percentage: 10.58%\n",
      "Topic 5 insincere percentage: 3.40%\n",
      "Topic 6 insincere percentage: 3.34%\n",
      "Topic 7 insincere percentage: 4.63%\n",
      "Topic 8 insincere percentage: 2.30%\n",
      "Topic 9 insincere percentage: 8.08%\n",
      "Topic 10 insincere percentage: 4.96%\n",
      "Topic 11 insincere percentage: 4.68%\n",
      "Topic 12 insincere percentage: 11.16%\n",
      "Topic 13 insincere percentage: 7.49%\n",
      "Topic 14 insincere percentage: 5.32%\n",
      "Topic 15 insincere percentage: 7.07%\n",
      "Topic 16 insincere percentage: 7.91%\n",
      "Topic 17 insincere percentage: 7.45%\n",
      "Topic 18 insincere percentage: 8.83%\n",
      "Topic 19 insincere percentage: 2.77%\n",
      "Topic 20 insincere percentage: 5.23%\n",
      "Topic 21 insincere percentage: 4.13%\n",
      "Topic 22 insincere percentage: 7.36%\n",
      "Topic 23 insincere percentage: 1.71%\n",
      "Topic 24 insincere percentage: 4.79%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# distribution = model.transform(count_data)\n",
    "assignment = np.argmax(distribution, axis=-1)\n",
    "percs = []\n",
    "for i in range(topic_count):\n",
    "    i_topic = data.iloc[assignment == i]\n",
    "    insincere_perc = len(i_topic[i_topic[\"target\"] == 1]) / len(i_topic) * 100.0\n",
    "    print(\"Topic {:d} insincere percentage: {:.2f}%\".format(i, insincere_perc))\n",
    "    percs.append(insincere_perc)\n",
    "\n",
    "ax = plt.subplot()\n",
    "ax.bar(range(topic_count), percs)\n",
    "ax.set_xticks(range(topic_count))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write some code to calculate and show a bar chart denoting the percentages(and/or count) of each topic contributing to the number of insincere questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specific topics have an disproportionate amount of insincere questions. Use `.sample` to take some questions from the topic with the highest and lowest percentage of insincere questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest topic samples:\n",
      "\tIf a person doesn't know whether to talk to themselves when at home, should they be allowed to arrange a press conference to settle the matter?\n",
      "\tHow do I fool Indian people?\n",
      "\tWhere is Lisa Eldridge coming in India? Does anyone know the city?\n",
      "\tWhat are some gluten free sohan papdi recipes?\n",
      "\tHow can I deal with rude people and not get nervous?\n",
      "\tAre network sockets used for mobile network programming/mobile apps?\n",
      "\tWhat are the five wonders of people?\n",
      "\tIs Ayurveda not working properly for people?\n",
      "\tHow do you pronounce Dritsas?\n",
      "\tHow do we know there are exactly 2 electric charges?\n",
      "Lowest topic samples:\n",
      "\tIs there any way to make existential anxiety go away?\n",
      "\tWhat do appendix operation scars look like? How do you determine if it is one?\n",
      "\tWhich are the top web development companies in India?\n",
      "\tWho is the best iOS app development company in Germany?\n",
      "\tWhat is demonstrative communication?\n",
      "\tIs there a distinction between a software library and a software framework?\n",
      "\tWhat are your problems with becoming professional Java developer?\n",
      "\tWhat is cloud in software?\n",
      "\tHow is proton and electron interlinkef?\n",
      "\tWhich is the best way to learn hacking at home?\n"
     ]
    }
   ],
   "source": [
    "state = 5\n",
    "\n",
    "highest_idx = ...\n",
    "highest_samples = data.iloc[assignment == highest_idx].sample(n=10, random_state=state)\n",
    "print(\"Highest topic samples:\\n\\t{:s}\".format(\"\\n\\t\".join(highest_samples[\"raw_text\"])))\n",
    "lowest_idx = ...\n",
    "lowest_samples = data.iloc[assignment == lowest_idx].sample(n=10, random_state=state)\n",
    "print(\"Lowest topic samples:\\n\\t{:s}\".format(\"\\n\\t\".join(lowest_samples[\"raw_text\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative: Build the topic model on solely insincere data\n",
    "\n",
    "Flipping the question since we now know that insincere questions tend to gravitate toward specific topics: Can we instead isolate the specific topics directly from the insincere portions of the data? Let's try it out. \n",
    "\n",
    "Build the same topic model and extract related topics just as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "From the distribution above, we can clearly detect some words that are hotbeds for inflamatory purpose, for example, *\"trump\"*. Let's plug it back into our dataset as a keywords and see how many insincere questions are asked with it and how many isn't.\n",
    "\n",
    "Set `safe_check` to False to trade accuracy for speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage for keyword \"trump\": 43.01%\n"
     ]
    }
   ],
   "source": [
    "def keyword_percentage(dataframe, word, safe_check=True):\n",
    "    if(safe_check):\n",
    "        checker_fn = lambda text: word in text.lower().strip().split()\n",
    "    else:\n",
    "        checker_fn = lambda text: word in text.lower()\n",
    "    contain = dataframe[dataframe[\"tokenized_text\"].map(checker_fn)]\n",
    "    try:\n",
    "        return float(len(contain[contain[\"target\"] == 1])) / len(contain)\n",
    "    except ZeroDivisionError:\n",
    "        return 0.0\n",
    "\n",
    "test_keyword = \"trump\"\n",
    "print(\"Percentage for keyword \\\"{:s}\\\": {:.2f}%\".format(test_keyword, keyword_percentage(data, test_keyword) * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could easily streamline the process for the topic words generated from the model. With **3** best words per topic, display the above insincere percentage for each of them in another <u>bar chart</u>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional: sample a number of random keyword (say, 5 of them) in the dataset and draw them on the bar chart along the other values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is pretty clear that many keywords constitute a fair amount of abuse, with special cases have more than 40% of their question flagged as insincere. These keywords can be used in conjuntion with other classification methods to catch most insincere questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Advanced methods and alternatives\n",
    "\n",
    "### Non-Negative Matrix Factorization\n",
    "An alternative choice for topic modeling that we haven't had the chance to explore is Non-Negative Matrix Factorization (<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html#sklearn.decomposition.NMF\">link</a>). You can redo the above case with this module instead and see if the result improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of Classification\n",
    "\n",
    "Student who had ran through the previous Classification course can try tackle this problem and see if the new insights offered in this notebook would translate to a higher accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
